from OpenAiGym.MinTermSrpobfEnv.MinTermSrpobfEnv import MinTermSrpobfEnv, ActionType
import torch as th
from stable_baselines3 import PPO, A2C, DQN, DDPG
policy_kwargs = dict(activation_fn=th.nn.ReLU,
                     net_arch=[500, 500])
act = ActionType.INCREASE

env= MinTermSrpobfEnv(44176,4,False,act,False,episodic_reward=False)

macro_step = 0
for step in range(60000000):
    observation, returned_reward, done, info = env.step(env.action_space.sample())
    if done:
        env.reset()

    if step%100000 == 0:
        print("Continues... " + str(macro_step))
        macro_step += 1

model = DQN('MlpPolicy', env,  policy_kwargs=policy_kwargs, verbose=1)
model.learn(total_timesteps=2000000)

obs = env.reset()
for i in range(100):
    action, _state = model.predict(obs, deterministic=True)
    obs, reward, done, info = env.step(action)
    print(obs)
    if done:
      print(obs)
      break
      obs = env.reset()

envs["4_0xaba4"].calculate_weights(k)
array([  0.,  16.,   0.,   0.,   0., -16.,   0.,   0.,   8.,   0.,   0.,
         8.,   0.,  -8.,   8.,   0.])

from OpenAiGym.RLAlgorithmRunners.DqnRunner.DqnRunner import dqn_runner
metrics, envs=dqn_runner(5,"/home/oytun/PycharmProjects/research/OpenAiGym/MinTermSrpobfEnv/Data/5dim/DQN/2",[11,16])
three_immediate_reward = dqn_runner(3,False)
three_episode_reward = dqn_runner(3,True)
four_immediate_reward = dqn_runner(4,False)
four_episode_reward = dqn_runner(4,True)

from OpenAiGym.RLAlgorithmRunners.RandomActionRunner.RandomActionRunner import random_action_runner
random_action_runner(5,"/home/oytun/PycharmProjects/research/OpenAiGym/MinTermSrpobfEnv/Data/5dim/RandomAction")
three_reward = random_action_runner(3)
four_reward = random_action_runner(4)

from OpenAiGym.RLAlgorithmRunners.RandomKVectorRunner.RandomKVectorRunner import random_k_vector_runner
random_k_vector_runner(5,"/home/oytun/PycharmProjects/research/OpenAiGym/MinTermSrpobfEnv/Data/5dim/RandomKVector")
three_reward = random_k_vector_runner(3)
four_reward = random_k_vector_runner(4)

dqn_runner(5,"/home/oytun/PycharmProjects/research/OpenAiGym/MinTermSrpobfEnv/Data/Visuals/5dim/DQN",[12,13])

import json

json_file_name = "four_episode_reward" + ".json"
json_handle = json.dumps(four_episode_reward)
f = open(json_file_name,"w")
f.write(json_handle)
f.close()

with open(json_file_name) as json_file:
    data = json.load(json_file)

import matplotlib.pyplot as plt
plt.plot(three_reward["3_172_max_reward"])
plt.show()
Max_Reward

plt.plot(four_immediate_reward["4_47957_episode_total_reward"])
plt.show()
Cumulative_Reward_Immediate_Reward

plt.plot(four_episode_reward["4_47957_max_reward"])
plt.show()
Max_Reward_Episode_Reward
